{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3 (ipykernel) (diffusion.ipynb)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Server Not found"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "import platform\n",
    "platform.node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, json, argparse, time\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch as th\n",
    "from transformers import set_seed\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from diffuseq.utils import dist_util\n",
    "from diffuseq.text_datasets import load_data_text\n",
    "from diffuseq.rounding import denoised_fn_round\n",
    "from basic_utils import (\n",
    "    load_defaults_config,\n",
    "    create_model_and_diffusion,\n",
    "    add_dict_to_argparser,\n",
    "    args_to_dict,\n",
    "    load_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 102\n",
    "\n",
    "model_dir = \"/srv/nlprx-lab/share6/dheineman3/diffusion/DiffuSeq/diffusion_models/\"\n",
    "# model_name = \"diffuseq_dialogue_h128_lr0.0001_t2000_sqrt_lossaware_seed102_ts20230310-12:47:26\"\n",
    "model_name = \"diffuseq_dialogue_h128_lr0.0001_t2000_sqrt_lossaware_seed102_ts20230402-13:09:56\"\n",
    "model_path = model_dir + model_name\n",
    "out_dir = 'generation_outputs'\n",
    "\n",
    "# Get last checkpoint\n",
    "checkpoints = sorted(glob.glob(f\"{model_path}/ema*.pt\"))[::-1]\n",
    "checkpoint_path = checkpoints[0]\n",
    "\n",
    "# Load model config (add default values if they don't exist)\n",
    "config_path = f\"{model_path}/training_args.json\"\n",
    "args = load_defaults_config()\n",
    "with open(config_path, 'rb', ) as f:\n",
    "    train_args = json.load(f)\n",
    "    for k, v in train_args.items():\n",
    "        args[k] = v\n",
    "args.update(dict(\n",
    "    clamp_step=0, seed2=105, clip_denoised=False,\n",
    "    model_path = model_dir,\n",
    "    split = 'test',\n",
    "    data_dir = 'datasets/TS-small', # During test, we don't want that many sentences\n",
    "    batch_size = 2, # Inference on one sentence at a time!\n",
    "    step = 2000,\n",
    "    top_p = -1,\n",
    "    pattern = 'ema'\n",
    "))\n",
    "\n",
    "# Unfortunately some functions want arguments using the arguments library\n",
    "# this is not possible in notebooks so we convert the dict to an object with\n",
    "# entries as properties instead.\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "args_obj = Struct(**args)\n",
    "\n",
    "# Get total model name\n",
    "model_base_name = os.path.basename(os.path.split(checkpoint_path)[0]) + f'.{os.path.split(checkpoint_path)[1]}'\n",
    "\n",
    "# Create output directories\n",
    "out_dir = os.path.join(out_dir, f\"{model_base_name.split('.ema')[0]}\")\n",
    "out_path = os.path.join(out_dir, f\"ema{model_base_name.split('.ema')[1]}.samples\")\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "if not os.path.isdir(out_path):\n",
    "    os.mkdir(out_path)\n",
    "out_path = os.path.join(out_path, f\"seed{args_obj.seed2}_step{args_obj.clamp_step}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameter count: 91225274\n",
      "Is CUDA: True\n"
     ]
    }
   ],
   "source": [
    "model, diffusion = create_model_and_diffusion(**args)\n",
    "model.load_state_dict(\n",
    "    dist_util.load_state_dict(checkpoint_path, map_location=\"cpu\")\n",
    ")\n",
    "model.eval().requires_grad_(False).to('cuda') #.to(dist_util.dev())\n",
    "print(f'Total parameter count: {sum(p.numel() for p in model.parameters())}')\n",
    "print(f'Is CUDA: {next(model.parameters()).is_cuda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer(args_obj)\n",
    "model_emb = th.nn.Embedding(\n",
    "    num_embeddings=tokenizer.vocab_size, \n",
    "    embedding_dim=args_obj.hidden_dim, \n",
    "    _weight=model.word_embedding.weight.clone().cpu()\n",
    ").eval().requires_grad_(False)\n",
    "model_emb.to('cuda') #.to(dist_util.dev())\n",
    "set_seed(args_obj.seed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset dialogue from datasets/TS-small...\n",
      "### Loading form the TEST set...\n",
      "### Data samples...\n",
      " [\"Lata Mondal ( ; born: 16 January 1993, Dhaka) is a Bangladeshi cricketer who plays for the Bangladesh national women's cricket team.\", 'She is a right handed batter.'] [\"Lata Mondal (born: 16 January 1993) is a Bangladeshi cricketer who plays for the Bangladesh national women's cricket team.\", 'She is a right handed bat.']\n",
      "RAM used: 1957.54 MB\n",
      "Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 200\n",
      "})\n",
      "RAM used: 1959.55 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af75200653cc4f07b8ed57855396eb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 200\n",
      "})\n",
      "### tokenized_datasets...example [101, 2474, 2696, 12256, 9305, 1006, 1025, 2141, 1024, 2385, 2254, 2857, 1010, 16479, 1007, 2003, 1037, 24267, 9490, 2040, 3248, 2005, 1996, 7269, 2120, 2308, 1005, 1055, 4533, 2136, 1012, 102]\n",
      "RAM used: 1962.15 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d2ca19ea014d939b0cd9ef4a4e677b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 1964.71 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b8670fb01141c585d0cf38568f0f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 200\n",
      "}) padded dataset\n",
      "RAM used: 1965.69 MB\n",
      "RAM used: 1965.69 MB\n",
      "End of reading iteration...\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "data_valid = load_data_text(\n",
    "    batch_size=args_obj.batch_size,\n",
    "    seq_len=args_obj.seq_len,\n",
    "    deterministic=True,\n",
    "    data_args=args_obj,\n",
    "    split=args_obj.split,\n",
    "    loaded_vocab=tokenizer,\n",
    "    model_emb=model_emb.cpu(),  # using the same embedding weight with tranining data\n",
    "    loop=False\n",
    ")\n",
    "\n",
    "# Extract data from dataloader to list\n",
    "all_test_data = []\n",
    "try:\n",
    "    while True:\n",
    "        batch, cond = next(data_valid)\n",
    "        all_test_data.append(cond)\n",
    "except StopIteration:\n",
    "    print('End of reading iteration...')\n",
    "\n",
    "print(len(all_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378fd5fb96a44a749dee33e73eb4979a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_kwargs = {}\n",
    "\n",
    "# Get & embed input sentence\n",
    "cond = all_test_data[0].copy()\n",
    "input_ids_x, input_ids_mask = cond.pop('input_ids').to('cuda'), cond.pop('input_mask').to('cuda')\n",
    "x_start, input_ids_mask_ori = model.get_embeds(input_ids_x), input_ids_mask\n",
    "\n",
    "# Create randomly noised input\n",
    "noise = th.randn_like(x_start)\n",
    "input_ids_mask = th.broadcast_to(input_ids_mask.unsqueeze(dim=-1), x_start.shape) # .to(dist_util.dev())\n",
    "x_noised = th.where(input_ids_mask == 0, x_start, noise)\n",
    "\n",
    "# Use DDIM sampling if the step size is not the same as the trained step size\n",
    "if args_obj.step == args_obj.diffusion_steps:\n",
    "    args_obj.use_ddim = False\n",
    "    step_gap = 1\n",
    "else:\n",
    "    args_obj.use_ddim = True\n",
    "    step_gap = args_obj.diffusion_steps // args_obj.step\n",
    "\n",
    "# Setup and run sample loop\n",
    "sample_fn = (\n",
    "    diffusion.p_sample_loop if not args_obj.use_ddim else diffusion.ddim_sample_loop\n",
    ")\n",
    "\n",
    "sample_shape = (x_start.shape[0], args_obj.seq_len, args_obj.hidden_dim)\n",
    "\n",
    "samples = sample_fn(\n",
    "    model,\n",
    "    sample_shape,\n",
    "    noise=x_noised,\n",
    "    clip_denoised=args_obj.clip_denoised,\n",
    "    denoised_fn=partial(denoised_fn_round, args, model_emb),\n",
    "    model_kwargs=model_kwargs,\n",
    "    top_p=args_obj.top_p,\n",
    "    clamp_step=args_obj.clamp_step,\n",
    "    clamp_first=True,\n",
    "    progress=True,\n",
    "    mask=input_ids_mask,\n",
    "    x_start=x_start,\n",
    "    gap=step_gap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like you can implement guided diffusion using langevin_fn, but it is only implemented\n",
    "# for ddim. So let's try ddim and we can add length control as a Langevin function?\n",
    "\n",
    "encoded_partial_seq = [th.LongTensor([0])] # \"Partial sequence\" here is simply [BOS]\n",
    "print(encoded_partial_seq)\n",
    "assert len(encoded_partial_seq) == 1\n",
    "\n",
    "right_length = args.image_size ** 2 - len(encoded_partial_seq[0])\n",
    "right_pad = th.empty(right_length).fill_(todo_pad_token).long()\n",
    "print(right_pad, right_length, len(encoded_partial_seq[0]))\n",
    "\n",
    "encoded_partial_seq = [th.cat([seq, right_pad], dim=0) for seq in encoded_partial_seq]\n",
    "encoded_partial_seq[0][target_length - 1] = tokens2id['END']\n",
    "print(encoded_partial_seq[0], todo_pad_token)\n",
    "\n",
    "partial_mask = (encoded_partial_seq[0] == todo_pad_token).unsqueeze(0).expand(args.batch_size, -1)\n",
    "label = encoded_partial_seq[0]\n",
    "label_ids = th.tensor(label).unsqueeze(0)\n",
    "label_ids = label_ids.masked_fill(label_ids == todo_pad_token, 3)\n",
    "tgt_embs = model3.cuda()(label_ids.cuda())\n",
    "\n",
    "# Here's their Langevin function!\n",
    "langevin_fn_selected = partial(langevin_fn_length, 0.01, diffusion, partial_mask, model,\n",
    "                                tgt_embs.expand(args.batch_size, -1, -1), 0.1)\n",
    "def langevin_fn_length(coeff, diffusion, partial_mask, diff_model, tgt_embs, step_size, sample, mean, sigma,\n",
    "                       alpha, t, prev_sample):\n",
    "    K = 0 if t[0].item() < 10 else 3\n",
    "    tt = t[0].item() - 1 if t[0].item() > 0 else 200\n",
    "\n",
    "    input_embs_param = th.nn.Parameter(sample)\n",
    "    # input_embs = th.cat([input_embs_param, tgt_embs], dim=1)\n",
    "    # debug_lst.append(get_score(input_embs, label_ids2, model_control, t=tt))\n",
    "\n",
    "    with th.enable_grad():\n",
    "        for i in range(K):\n",
    "            optimizer = th.optim.Adagrad([input_embs_param], lr=step_size)\n",
    "            optimizer.zero_grad()\n",
    "            print(t.shape)\n",
    "            out = diffusion.p_mean_variance(\n",
    "                diff_model,\n",
    "                input_embs_param,\n",
    "                t,\n",
    "                clip_denoised=False,\n",
    "                denoised_fn=None,\n",
    "                model_kwargs={},\n",
    "            )\n",
    "            coef = coeff\n",
    "            if sigma.mean() == 0:\n",
    "                logp_term = coef * ((mean - input_embs_param) ** 2 / 1.).mean(dim=0).sum()\n",
    "                infill_loss = (out['pred_xstart'][~partial_mask] - tgt_embs[~partial_mask]) ** 2\n",
    "                infill_loss = infill_loss.mean(dim=0).sum()\n",
    "            else:\n",
    "                logp_term = coef * ((mean - input_embs_param)**2 / sigma).mean(dim=0).sum()\n",
    "                infill_loss = ((out['pred_xstart'][~partial_mask] - tgt_embs[~partial_mask]) ** 2).view(tgt_embs.size(0), -1, tgt_embs.size(-1) )\n",
    "                infill_loss = (infill_loss/sigma.mean()).mean(dim=0).sum()\n",
    "            print(infill_loss, f'start_{i}', logp_term.item(), t[0].item(), sigma.mean().item())\n",
    "            loss = logp_term + infill_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epsilon = th.randn_like(input_embs_param.data)\n",
    "            input_embs_param = th.nn.Parameter((input_embs_param.data + 0.0*sigma.mean().item() * epsilon).detach())\n",
    "            # input_embs_param = th.nn.Parameter((input_embs_param.data + np.sqrt(2*sigma.mean().item()) * epsilon).detach())\n",
    "    # model_out = model_control(input_embs=input_embs_param, pos_ids=label_ids, t=tt)\n",
    "    # print(model_out.loss, 'end')\n",
    "    return input_embs_param.data\n",
    "\n",
    "# Here's the DDIM sample loop they use:\n",
    "loop_func_(\n",
    "    model,\n",
    "    sample_shape,\n",
    "    denoised_fn=partial(denoised_fn_round, args, model3.cuda()),\n",
    "    # denoised_fn=partial(langevin_early, model_control, model3.cuda(),\n",
    "    #                     label_ids.expand(args.batch_size, -1), 0.1),\n",
    "    clip_denoised=args.clip_denoised,\n",
    "    model_kwargs=model_kwargs,\n",
    "    device=encoded_seq_hidden.device,\n",
    "    langevin_fn=langevin_fn_selected,\n",
    "    eta=args.eta,\n",
    "    # langevin_func=partial(langevin_func, model_control,\n",
    "    #                       label_ids.expand(args.batch_size, -1), 0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] lata mondal ( born : 16 january 1993 ) is a bangladeshi cricketer who plays for the bangladesh national women's cricket team. [SEP]\n",
      "[CLS] lata mondal ( born 16 january 1993, dhaka ) is a canadian bangladeshi music cricketer. [SEP]\n"
     ]
    }
   ],
   "source": [
    "sample = samples[-1]\n",
    "\n",
    "logits = model.get_logits(sample)\n",
    "cands = th.topk(logits, k=1, dim=-1)\n",
    "\n",
    "word_lst_recover, word_lst_ref, word_lst_source = [], [], []\n",
    "\n",
    "# Recover original & reference sentences\n",
    "for seq, input_mask in zip(input_ids_x, input_ids_mask_ori):\n",
    "    len_x = args_obj.seq_len - sum(input_mask).tolist()\n",
    "    word_lst_source += [tokenizer.decode_token(seq[:len_x])]\n",
    "    word_lst_ref += [tokenizer.decode_token(seq[len_x:])]\n",
    "\n",
    "# Recover decoded output\n",
    "for seq, input_mask in zip(cands.indices, input_ids_mask_ori):\n",
    "    len_x = args_obj.seq_len - sum(input_mask).tolist()\n",
    "    tokens = tokenizer.decode_token(seq[len_x:])\n",
    "    word_lst_recover += [tokens]\n",
    "\n",
    "print(word_lst_ref[0])\n",
    "print(word_lst_recover[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sents = []\n",
    "for sample in samples:\n",
    "    logits = model.get_logits(sample)\n",
    "    cands = th.topk(logits, k=1, dim=-1)\n",
    "\n",
    "    word_lst_recover, word_lst_ref, word_lst_source = [], [], []\n",
    "\n",
    "    # Recover original & reference sentences\n",
    "    for seq, input_mask in zip(input_ids_x, input_ids_mask_ori):\n",
    "        len_x = args_obj.seq_len - sum(input_mask).tolist()\n",
    "        word_lst_source += [tokenizer.decode_token(seq[:len_x])]\n",
    "        word_lst_ref += [tokenizer.decode_token(seq[len_x:])]\n",
    "\n",
    "    # Recover decoded output\n",
    "    for seq, input_mask in zip(cands.indices, input_ids_mask_ori):\n",
    "        len_x = args_obj.seq_len - sum(input_mask).tolist()\n",
    "        tokens = tokenizer.decode_token(seq[len_x:])\n",
    "        word_lst_recover += [tokens]\n",
    "\n",
    "    # print(word_lst_ref[0])\n",
    "    step_sents += [word_lst_recover[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3297/3896993736.py:25: UserWarning: frames=None which we can infer the length of, did not pass an explicit *save_count* and passed cache_frame_data=True.  To avoid a possibly unbounded cache, frame data caching has been disabled. To suppress this warning either pass `cache_frame_data=False` or `save_count=MAX_FRAMES`.\n",
      "  animation = FuncAnimation(fig, animation_func,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b01e1681ce54346b44cbc1461697349",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=700.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create animation\n",
    "# basically will be a mat plot graph with highlighted text\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import random\n",
    "import numpy as np\n",
    "  \n",
    "x = []\n",
    "y = []\n",
    "colors = []\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "  \n",
    "def animation_func(i):\n",
    "    x.append(random.randint(0,100))\n",
    "    y.append(random.randint(0,100))\n",
    "    colors.append(np.random.rand(1))\n",
    "    area = random.randint(0,30) * random.randint(0,30)\n",
    "    plt.xlim(0,100)\n",
    "    plt.ylim(0,100)\n",
    "    plt.scatter(x, y, c = colors, s = area, alpha = 0.5)\n",
    "  \n",
    "animation = FuncAnimation(fig, animation_func, \n",
    "                          interval = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write outputs to file\n",
    "fout = open(out_path, 'a')\n",
    "for (recov, ref, src) in zip(word_lst_recover, word_lst_ref, word_lst_source):\n",
    "    print(json.dumps({\"recover\": recov, \"reference\": ref, \"source\": src}), file=fout)\n",
    "fout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
